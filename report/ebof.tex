\documentclass[a4paper,twoside, openright,12pt]{report}
\usepackage{psfrag,amsbsy,graphics,float}
\usepackage{graphicx, color} %Deleted [dvips] in front of {graphicx, color} for usage also with PDFLaTex
\usepackage[latin1]{inputenc}
\usepackage{verbatim}
\usepackage{amsthm}

% for pseudocode
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pifont}

%For Subfigures_________
\usepackage{subcaption}

%For comments
\newcommand{\edit}[2]{{{\textcolor{blue}{#1}}\emph{\textcolor{red}{#2}}}}



\newtheorem{defwrp}{Definition}
% based on the LSR Student Template, last change: 2014-06-05

%_______Kopf- und Fußzeile_______________________________________________________
\usepackage{fancyhdr}
\pagestyle{fancy}
%um Kopf- und Fußzeile bei chapter-Seiten zu reaktivieren
\newcommand{\helv}{%
   \fontfamily{phv}\fontseries{a}\fontsize{9}{11}\selectfont}
\fancypagestyle{plain}{
	\fancyfoot{}% keine Fußzeile
	\fancyhead[RE]{\helv\leftmark}% Rechts auf geraden Seiten=innen; in \leftmark stehen \chapters
	\fancyhead[LO]{\helv\rightmark}% Links auf ungeraden Seiten=außen;in \rightmark stehen \sections
	\fancyhead[RO,LE]{\thepage}}%Rechts auf ungeraden und links auf geraden Seiten
%Kopf- und Fußzeile für alle anderen Seiten
\fancyfoot{}
\fancyhead[RE]{\helv\leftmark}
\fancyhead[LO]{\helv\rightmark}%alt:\fancyhead[LO]{\itshape\rightmark}
\fancyhead[RO,LE]{\thepage}
%________________________________________________________________________________


%_Definieren der Ränder und Längen__________
\setlength{\textwidth}{15cm}
\setlength{\textheight}{22cm}
\setlength{\evensidemargin}{-2mm}
\setlength{\oddsidemargin}{11mm}
\setlength{\headwidth}{15cm}
\setlength{\topmargin}{10mm}
\setlength{\parindent}{0pt} % Kein Einrücken beim Absatz!!
%___________________________________________

%_Hyperref for CC Url__________
\usepackage{hyperref}
%___________________________________________

%_______Title Page__________________________________________
\begin{document}
\pagestyle{empty}
\enlargethispage{4.5cm} %Damit das Titelbild weit genug unten ist!
\begin{center}
\phantom{u}
\vspace{0.5cm}
\Huge{\sc An Efficient Event-Based Optical Flow Implementation in C/C++ and CUDA}\\
\vspace{1.5cm}
		\large{
			PROJECT REPORT\\%i.e. DIPLOMA THESIS, BACHELOR THESIS, ADVANCED SEMINAR,
			%Intermediate Report\\
			\vspace{0.4cm}
			submitted by\\
			Adam Kosiorek,
			David Adrian,
			Johannes Rausch\\
			% if this is a diploma/bachelor/master thesis include the following:
			%\vspace{0.5cm}
			%born on: DD.MM.YYYY\\
			%\vspace{0.5cm}
			%Streetname XX \\
			%Zipcode City \\
			%Tel.: xxx\,xxxxxxxx \\
			\vspace{1.5cm}
			NEUROSCIENTIFIC SYSTEM THEORY\\
			Technische Universit\"at M\"unchen\\
			\vspace{0.3cm}
			Prof. Dr J\"org Conradt\\
		}
\end{center}
\vspace{5.5cm}
\begin{tabular}{ll}
Supervisor: & Dipl.-Inf. Nicolai Waniek\\
% add the start and intermediate report dates for DA/BA/MA thesis
%Start: & xx.xx.201x  \\
%Intermediate Report: &  xx.xx.201x  \\
Final Submission: &  07.07.2015 \\
\end{tabular}
%____________________________________________________________

\newpage
% \cleardoublepage

%_______Abstract_____________________________________________
\topmargin5mm
\textheight220mm
\pagenumbering{arabic}
\phantom{u}
\begin{abstract}
  Optic flow detection is a fundamental problem in computer vision.
  It describes the change of structured light in an observed scene by a camera or the human eye.
  The change can hereby be caused by either moving objects in the scene, ego-motion of the observer, or both.
  While it is a well-known problem with many existing solutions when using RGB cameras producing full frames at a frequency $f$, it is still an unsolved problem for Dynamic Vision Sensors (DVS).
  Producing only a sparse event stream, a DVS reports temporal changes in luminance on a per-pixel basis.
  Deriving the spatial change of the scene is thus a much more complex problem than with dense images - particularly those produced at a well-known and fixed frequency.
  This makes it considerably more difficult to compute an optic flow field for a sparse event stream, as it relies on both temporal and spatial information.
  This project report deals with the implementation and evaluation of a novel, biologically motivated approach to compute the optic flow for an event stream using a filter bank of spatio-temporal Gabor filters.
\end{abstract}
%____________________________________________________________


\pagestyle{fancy}

%_________Inhaltsverzeichnis__________________________
\tableofcontents
%_____________________________________________________

%_________Einleitung__________________________________
\chapter{Introduction}

\textit{Optic flow} describes the change of light in a scene, as perceived by a camera or the human eye, caused by motion of objects in the scene or ego-motion of the observing entity.
Using optic flow information, \edit{it is possible to infer the motion of objects and, consequently, segment a scene based on it into disjunct moving objects.}{scene based on what?}
In engineering applications it is used, for example, in video compression to interpolate between frames or in stereo vision applications.

\section{Problem Statement}

Typical cameras produce full frames at a fixed frequency of \emph{e.g.} 30 frames per second.
This implies that regardless of change in the scene, and thus available information, new frames are produced.
In the context of optic flow it is, however, much easier to estimate the flow, \edit{as looking at two frames produced at times $t_n,t_{n+1}$, they are discretized in time, but also the spatial changes are discretized.}{I don't get it. What's with the discretization?}

Event-based sensors, such as the DVS \cite{Delbruck}, offer a new \edit{paradigm in computer vision.}{that's a strong statement. What's new about it?} 
The DVS can register changes in light intensity for individual pixels asynchronously.

However, events are highly ambiguous and carry information only about the direction of intensity change at a given time and location.
\edit{Due to the event-based nature, many computer vision algorithms can not directly be applied when using Dynamic Vision Sensors.}{it says that the algorithms can't be applied because they have event-based nature, which is not true}

Consequently, there has only been little progress with regards to translating optical flow algorithms to the sparse event-stream created by a DVS.
\edit{TODO: Here a bit about the failed attempts from others (need for next section?)}
In \cite{Brosch2015}, recently Brosch et al. describe a novel biologically motivated approach to infer the optic flow field by convolving the sparse event stream with Gabor filter bank.

The goal of this project is to implement the algorithm designed by Brosch et al. in an efficient general-purpose language and evaluate if and how it can be run under real-time constraints.
For this purpose, an implementation in C++ with support for CUDA has been chosen.
In the following, the design decisions and implementation details are described, as well as a thorough evaluation, both quantitative and qualitative, is presented.

\section{Related Work}

Here we gonna talk about the paper we gonna implement (or in the section above).
But definitely give a very short summary about other approaches and implementations (if we can find any public).

%____________________________________________________



%_____Kapitel 2_________________________________
\chapter{Implementation of the Algorithm}

\input{algorithm.tex}
\input{code_design.tex}
\input{implementation.tex}

% Kapitel 3
\chapter{Evaluation and Discussion}
\input{experimental_results.tex}
\input{discussion.tex}

%_______________________________________________


%_____Zusammenfassung, Ausblick_________________________________
\chapter{Conclusion}

We did/showed:
After ensuring the correctness of the algorithm, we pursued different approaches in parallelizing the code in order to achieve real-time capabilities.

%- Evaluate the correctness of the proposed algorithm in Matlab
- Sequential C++ Impl (FFT) not real-time capable (mention if results exist)
- Parallel C++ Impl (FFT/CUDA) real-time capable
- Showed real-time capabilities with regards to parallel impl

The qualitative analysis showed that the investigated algorithm can properly compute optic flow on an event-based basis.
Especially objects that move perpendicularly to the orientation of their edges are recognized very well.
In order to ensure accurate results in all cases, additional response normalization has to be performed in the post-processing.
It is also notable that the algorithm is not heavily affected by rather random noise in the image such as events on the floor or background in the case of a moving camera.

What doesn't work yet specific to our impl? 
-Normalization
-Efficient CUFFT interface
-other smaller things???




Give very short outlook here:
-stereo vision
-feature detection

% Apendix
\input{appendix.tex}
%_______________________________________________________________


%_____Abbildungsverzeichnis_________________________________
\cleardoublepage
\addcontentsline{toc}{chapter}{List of Figures}
\listoffigures 	 %Abbildungsverzeichnis

%___________________________________________________________

%_____Literaturverzeichnis_________________________________
\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{ebof.bib}
\bibliographystyle{alphaurl}
%__________________________________________________________


%_____License_________________________________
\cleardoublepage
\chapter*{License}
\markright{LICENSE}
The MIT License (MIT)\\

Copyright (c) 2015 Adam Kosiorek, David Adrian, Johannes Rausch\\

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
%__________________________________________________________

\end{document}
